<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vijay Reddy | AI/ML Engineer</title>
  <link rel="stylesheet" href="style.css" />
<style>
  .collapsed .project {
    display: none;
  }
</style>
</head>
<body>
  <header>
    <h1>Hi, I'm Vijay Reddy ğŸ‘‹</h1>
    <p>Senior Data Scientist | AI/ML Engineer | Quantum ML Enthusiast</p>
    <a class="resume-button" href="https://drive.google.com/file/d/your-resume-link/view" target="_blank">ğŸ“„ Download Resume</a>
  </header>

  <section id="skills">
  <h2>Technical Skills</h2>
  <ul>
    <li><strong>Programming:</strong> Python, C, SQL</li>
    <li><strong>AI/ML Frameworks:</strong> TensorFlow, PyTorch, Scikit-learn, Keras</li>
    <li><strong>Deep Learning:</strong> CNN, LSTM, Transformers, GANs, RAG, Attention Mechanisms</li>
    <li><strong>Generative AI:</strong> OpenAI GPT-4, Gemini Pro, BART, T5, LLaMA2, LangChain</li>
    <li><strong>Databases & Tools:</strong> PostgreSQL, MySQL, MongoDB, ChromaDB, Pinecone</li>
    <li><strong>Web/App Development:</strong> Flask, Django, Streamlit, HTML/CSS/JS, Bootstrap</li>
    <li><strong>Version Control & Deployment:</strong> Git, GitHub, Docker, AWS EC2, Netlify</li>
    <li><strong>Others:</strong> Celery, Redis, FastAPI, Hugging Face Transformers, OpenCV</li>
  </ul>
</section>

<section id="about">
    <h2>About Me</h2>
    <p>M.Tech in Artificial Intelligence from IIT Jodhpur, passionate about AI, Quantum Computing, and solving real-world problems with innovative technologies. Experienced in deep learning, generative AI, and building production-grade solutions.</p>
  </section>

  <section id="education">
  <h2>Education</h2>
  <div class="project">
    <h3>ğŸ“ M.Tech in Artificial Intelligence</h3>
    <p><strong>Institute:</strong> Indian Institute of Technology (IIT) Jodhpur</p>
    <p><strong>Duration:</strong> 2021 â€“ 2023</p>
    <p><strong>CGPA:</strong> 7.00 / 10</p>
    <p><strong>Highlights:</strong></p>
    <ul>
      <li>Specialization in Deep Learning, NLP, Computer Vision, MLOps</li>
      <li>Published thesis on GAN-based high-resolution image enhancement</li>
      <li>Teaching Assistant for 6 courses including Deep Learning, DLOps, and Machine Learning</li>
    </ul>
  </div>
  <div class="project">
    <h3>ğŸ“ B.Tech in Electrical & Electronics Engineering</h3>
    <p><strong>Institute:</strong> Sree Vidyanikethan Engineering College</p>
    <p><strong>Duration:</strong> 2015 â€“ 2019</p>
    <p><strong>CGPA:</strong> 7.84 / 10</p>
  </div>
</section>

<section id="projects" class="collapsible collapsed">
    <h2>Industry Projects <button class="toggle-btn" onclick="toggleSection('projects')">â–¼</button></h2>

    <div class="project">
  <h3>ğŸš€ Solar Power Forecasting and Fault Detection</h3>
  <p><strong>Hybrid Deep Learning Approach using CNN + LSTM + Transformer</strong></p>
  <p>Built a highly accurate, end-to-end solar power forecasting pipeline using deep learning to tackle real-world energy optimization. The model integrates weather and inverter data, processes it using a hybrid CNNâ€“LSTMâ€“Transformer architecture, and supports real-time predictions (minute-wise and hourly) with fault detection capabilities.</p>

  <p><strong>ğŸ“Œ Key Features:</strong></p>
  <ul>
    <li>Hybrid architecture combining CNN (spatial features), LSTM (temporal patterns), and Transformer (global attention)</li>
    <li>Preprocessing of sensor data: GHI, POA, module temp, wind speed, humidity, inverter power</li>
    <li>Prediction of Active Power (kW), DC Power, and Todayâ€™s Generation (kWh)</li>
    <li>Correlation heatmaps and anomaly detection for real-time fault alerts</li>
    <li>Performance: MAE: 3.25%, MSE: 0.257%</li>
    <li>Presented at <strong>GCDEM 2024</strong> for its contribution to renewable energy systems</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> TensorFlow, Keras, Scikit-learn, Python, Matplotlib</p>
  <p><strong>ğŸ”—</strong> <a href="https://github.com/vkreddy317/solar-power-forecasting" target="_blank">View GitHub Repository</a></p>
</div>

    <div class="project">
  <h3>ğŸ§± Ultimeet â€“ AI-Powered Meeting Assistant</h3>
  <p><strong>Redefining Digital Meetings with AI + Voice Biometrics</strong></p>
  <p>Ultimeet is an end-to-end intelligent meeting platform that revolutionizes online meetings. It takes recorded audio/video from virtual meetings, transcribes them with high accuracy, separates speakers using biometric voice signatures, and generates detailed outputs like MoMs, action items, key decisions, and engagement analyticsâ€”all automatically.</p>

  <p><strong>ğŸ“Œ Key Capabilities:</strong></p>
  <ul>
    <li><strong>Voice Biometric Speaker Identification:</strong> Each participantâ€™s voice is uniquely recognized and tagged using advanced biometric fingerprinting, ensuring clarity and accountability.</li>
    <li><strong>Auto Transcription & MoM Generation:</strong> Converts meeting recordings into detailed transcripts and summarizes decisions, announcements, and discussions into a polished MoM report.</li>
    <li><strong>Action Items Extraction:</strong> Automatically detects task-related commitments and assigns them within an integrated task manager for tracking and follow-up.</li>
    <li><strong>Advanced Analytics:</strong> Visualizes speaker participation, topic durations, and sentiment insights using data-driven dashboards to optimize meetings.</li>
    <li><strong>Seamless Integrations:</strong> Works smoothly with CRMs, calendars, and communication platforms to embed AI features into everyday workflows.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> AssemblyAI, OpenAI GPT-4, Python, Flask, Redis, PostgreSQL, Streamlit</p>
  <p><strong>ğŸš€ Impact:</strong> Achieved 95% transcription accuracy, automated task tracking, and reduced manual documentation by over 80% across enterprise demos and internal deployments.</p>
</div>

    <div class="project">
  <h3>ğŸ¤– AI Chatbot with LLaMA2 + Markup LLM using RAG & Summarization</h3>
  <p><strong>Interactive Chat Assistant with Retrieval-Augmented Generation</strong></p>
  <p>This chatbot was integrated into a company portal with a responsive HTML interface. It uses Metaâ€™s LLaMA2 model for conversational AI, enhanced with a RAG (Retrieval-Augmented Generation) pipeline and Hugging Face-based summarization models for intelligent interaction with custom documents.</p>

  <p><strong>ğŸ“Œ Key Features:</strong></p>
  <ul>
    <li><strong>LLaMA2 Conversational AI:</strong> Fine-tuned for domain-specific query handling with context retention and coherent multi-turn dialogue.</li>
    <li><strong>RAG with Custom PDFs:</strong> Embeds and retrieves relevant information from internal documents to generate grounded responses.</li>
    <li><strong>Document Summarization:</strong> Supports both abstractive and extractive summarization using BART/Pegasus models.</li>
    <li><strong>Markup-Aware Parsing:</strong> Integrates a lightweight LLM for structured document understandingâ€”headers, lists, and tables.</li>
    <li><strong>Frontend Integration:</strong> Responsive chatbot UI with company intranet embedding and real-time interaction support.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> LLaMA2, Hugging Face Transformers, FAISS/ChromaDB, PyMuPDF, Flask, HTML/CSS/JS</p>
  <p><strong>ğŸŒ± Future Scope:</strong> Voice-based interaction, multilingual support, OCR/image-based doc processing, and analytics dashboard for usage insights.</p>
</div>

    <div class="project">
  <h3>ğŸ§  Natural Language to SQL using Google Generative AI in Streamlit</h3>
  <p><strong>Bridging the Gap Between Business Queries and SQL with Generative AI</strong></p>
  <p>Developed a user-friendly Streamlit application that translates plain English questions into executable SQL queries using Googleâ€™s Generative AI (PaLM/Gemini). The tool empowers non-technical users to access business data directly from databases without needing SQL expertise.</p>

  <p><strong>ğŸ“Œ Key Features:</strong></p>
  <ul>
    <li><strong>Natural Language Input:</strong> Accepts queries like "List top 10 products by revenue in 2023" and generates accurate SQL queries.</li>
    <li><strong>Schema-Aware Prompting:</strong> Shares table metadata dynamically to guide the LLM for valid SQL generation.</li>
    <li><strong>Interactive UI:</strong> Streamlit interface shows user query, generated SQL, and output data table in one view.</li>
    <li><strong>Error Handling:</strong> Captures SQL errors, allows query correction or schema edit, and provides retry options.</li>
    <li><strong>Live Query Execution:</strong> Connects to databases (PostgreSQL/SQLite) and executes generated SQL on the fly.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Streamlit, Google Generative AI (PaLM/Gemini Pro), Python, PostgreSQL, pdfplumber, ChromaDB</p>
  <p><strong>ğŸŒ± Future Scope:</strong> Explainable SQL, JOINs, schema autodiscovery, RBAC, data visualizations, and multilingual query support.</p>
</div>

    <div class="project">
  <h3>ğŸ“º YouTube Transcript Summarization Web App using Google Generative AI</h3>
  <p><strong>Objective:</strong> Automate the extraction and summarization of YouTube video transcripts into concise summaries (within 250 words) using Googleâ€™s Generative AI, delivered via a Streamlit interface.</p>

  <p><strong>ğŸ“Œ Architecture & Workflow:</strong></p>
  <ul>
    <li><strong>User Input:</strong> Paste YouTube URL and choose summary style (abstract, bullet points, or both).</li>
    <li><strong>Transcript Extraction:</strong> Fetches full transcripts using <code>youtube-transcript-api</code>, handles multilingual and unavailable transcripts, and cleans text.</li>
    <li><strong>Summarization:</strong> Prompts Google Generative AI with custom instructions for well-structured, digestible output.</li>
    <li><strong>Output:</strong> Displays summary with optional download support in .txt format.</li>
    <li><strong>File Handling:</strong> Uses <code>pathlib</code> for caching and future transcript support (PDF, etc.).</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Streamlit, Python, Google Generative AI (Gemini/PaLM), youtube-transcript-api, pathlib, (planned: PyPDF2)</p>

  <p><strong>ğŸŒŸ Highlights:</strong></p>
  <ul>
    <li>Efficient prompt engineering for accurate summaries</li>
    <li>Chunking long transcripts to stay within token limits</li>
    <li>Future-proof modular design (batch mode, multilingual support, Whisper integration)</li>
  </ul>

  <p><strong>ğŸ¯ Use Cases:</strong> Education, training content repurposing, quick lecture review, knowledge assistant</p>
</div>

<div class="project">
  <h3>ğŸ“„ Multi-PDF Interaction Platform using Google Generative AI + ChromaDB</h3>
  <p><strong>Objective:</strong> Enable users to query and explore multiple PDFs intelligently using a natural language interface powered by Generative AI and vector search.</p>

  <p><strong>ğŸ“Œ Architecture & Workflow:</strong></p>
  <ul>
    <li><strong>File Upload:</strong> Upload multiple PDFs via a Streamlit interface; files are processed and stored temporarily using <code>pathlib</code>.</li>
    <li><strong>Text Extraction:</strong> Raw text extracted from PDFs using <code>PyPDF2</code>, then preprocessed and chunked semantically.</li>
    <li><strong>Vector Embeddings:</strong> Text chunks are converted into vector embeddings and indexed in <code>ChromaDB</code>.</li>
    <li><strong>Query Interface:</strong> User enters a question; relevant chunks are retrieved via semantic search.</li>
    <li><strong>LLM Response:</strong> Retrieved context + user query is sent to Google Generative AI for a grounded response.</li>
    <li><strong>Output:</strong> Shows the AI answer along with optional reference highlights to original document sources.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Streamlit, Python, PyPDF2, ChromaDB, Google Generative AI (Gemini/PaLM)</p>

  <p><strong>ğŸŒŸ Highlights:</strong></p>
  <ul>
    <li>Multi-PDF vector indexing with real-time semantic retrieval</li>
    <li>Prompt-engineered LLM responses grounded in actual source material</li>
    <li>Handles empty PDFs, malformed docs, and non-text files gracefully</li>
  </ul>

  <p><strong>ğŸ¯ Use Cases:</strong> Legal research, policy analysis, technical documentation review, enterprise FAQ systems</p>
</div>

<div class="project">
  <h3>ğŸ± Nutritionist AI Doctor â€” Calorie Estimator from Food Images using Google Generative AI</h3>
  <p><strong>Objective:</strong> Build a vision-enabled AI assistant that estimates calorie content and nutritional insights from food images using Google Gemini Pro Vision, delivered through a user-friendly Streamlit web app.</p>

  <p><strong>ğŸ“Œ Architecture & Workflow:</strong></p>
  <ul>
    <li><strong>Image Upload:</strong> Supports food image uploads in JPG/PNG or PDFs (converted using <code>pdf2image</code>).</li>
    <li><strong>Vision Analysis:</strong> Passes each image to Gemini Pro Vision API with prompts to analyze and break down calorie estimation.</li>
    <li><strong>Structured Output:</strong> Lists identified food items, approximate portion sizes, individual and total calorie counts, and nutrition commentary.</li>
    <li><strong>UI Integration:</strong> Displays results in a clean Streamlit layout with download option for summaries.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Streamlit, Python, Google Gemini Pro Vision, pdf2image, PIL, pathlib</p>

  <p><strong>ğŸŒŸ Highlights:</strong></p>
  <ul>
    <li>Advanced multimodal prompt engineering for accurate food recognition and health tips</li>
    <li>Flexible input handling (images and PDFs)</li>
    <li>Modular architecture for future integration with mobile apps or wearable sync</li>
  </ul>

  <p><strong>ğŸ¯ Use Cases:</strong> Diet planning, clinical nutrition tracking, fitness app integration, restaurant nutrition menu automation</p>
</div>

<div class="project">
  <h3>ğŸ“‘ Resume Application Tracking (ATS) Optimizer using Google Generative AI</h3>
  <p><strong>Objective:</strong> Create a Streamlit-based app that compares resumes against job descriptions using Googleâ€™s Generative AI, offering tailored feedback to improve ATS scores and job-fit alignment.</p>

  <p><strong>ğŸ“Œ Architecture & Workflow:</strong></p>
  <ul>
    <li><strong>Resume Upload:</strong> Users upload a PDF resume and paste a job description.</li>
    <li><strong>Parsing:</strong> Resume text is extracted and cleaned using <code>PyPDF2</code>.</li>
    <li><strong>Prompted Evaluation:</strong> Google GenAI compares resume vs JD, highlighting matches, gaps, and keyword suggestions.</li>
    <li><strong>UI Display:</strong> Streamlit interface shows matched skills, gaps, recommendations, and optimized keywords. Feedback can be downloaded.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Streamlit, Python, PyPDF2, Google Generative AI (Gemini/PaLM)</p>

  <p><strong>ğŸŒŸ Highlights:</strong></p>
  <ul>
    <li>Dynamic prompt engineering for role-specific and industry-aligned feedback</li>
    <li>ATS-alignment scoring logic for section structure and keyword density</li>
    <li>Scalable design for resume batching, job board integration, and inline editing</li>
  </ul>

  <p><strong>ğŸ¯ Use Cases:</strong> Job seekers, career counselors, campus placement cells, AI-powered HR automation tools</p>
</div>
  </section>

  <section id="thesis-projects" class="collapsible collapsed">
    <h2>M.Tech Thesis Projects <button class="toggle-btn" onclick="toggleSection('thesis-projects')">â–¼</button></h2>
    <div class="project">
  <h3>ğŸ“· High-Resolution Image Enhancement using CinCGAN and RCAN</h3>
  <p><strong>Objective:</strong> Solve the single-image super-resolution problem in an unsupervised manner using GANs, without relying on paired HR-LR datasets or known downsampling kernels. This approach significantly improves degraded image quality affected by blur and noise.</p>

  <p><strong>ğŸ“Œ Methodology & Workflow:</strong></p>
  <ul>
    <li><strong>CinCGAN Framework:</strong> A novel Cycle-in-Cycle GAN architecture performs noise reduction and super-resolution in two stages using unpaired images.</li>
    <li><strong>Stage 1:</strong> Transforms noisy/blurry low-resolution images into clean bicubic-downsampled LR images using a CycleGAN with identity, adversarial, and TV losses.</li>
    <li><strong>Stage 2:</strong> Enhances resolution using RCAN (Residual Channel Attention Network), enabling fine-grained detail recovery via deep CNNs.</li>
    <li><strong>Joint Optimization:</strong> End-to-end fine-tuning of the pipeline ensures seamless noise removal and upsampling with high PSNR and SSIM.</li>
  </ul>

  <p><strong>ğŸ§  Model Insights:</strong></p>
  <ul>
    <li><strong>RCAN:</strong> Employs Residual-in-Residual (RIR), Residual Channel Attention Blocks (RCAB), and Channel Attention (CA) to prioritize meaningful features.</li>
    <li><strong>CinCGAN:</strong> Uses two nested CycleGANs with consistent mapping between noisy LR â†’ clean LR â†’ HR, optimized with custom loss functions.</li>
    <li><strong>Ablation Studies:</strong> Demonstrated effectiveness of each component (D1, D2, G2, G3) in denoising, restoring, and improving image sharpness.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Python, PyTorch, CycleGAN, RCAN, DIV2K Dataset</p>

  <p><strong>ğŸ“Š Results:</strong> Achieved performance competitive with state-of-the-art SISR models like EDSR and SRGAN â€” without using paired data. Validated on the Track-2 dataset from the NTIRE-2018 Super-Resolution Challenge.</p>

  <p><strong>ğŸ¯ Applications:</strong> Medical imaging, satellite photo enhancement, surveillance video restoration, real-world low-light image enhancement</p>
</div>
  </section>

  <section id="course-projects" class="collapsible collapsed">
    <h2>M.Tech Course Projects <button class="toggle-btn" onclick="toggleSection('course-projects')">â–¼</button></h2>
    <div class="project">
  <h3>âœï¸ POS Tagging using Hidden Markov Model (HMM)</h3>
  <p><strong>Objective:</strong> Build a sequence labeling system to tag each word in a sentence with its correct part-of-speech using probabilistic modeling based on Hidden Markov Models and Viterbi decoding.</p>

  <p><strong>ğŸ“Œ Methodology & Workflow:</strong></p>
  <ul>
    <li><strong>Corpus:</strong> Used Wall Street Journal (WSJ) dataset â€” sections 02â€“21 for training and section 24 for testing.</li>
    <li><strong>Model:</strong> Applied first-order HMM with supervised learning to derive transition and emission probabilities.</li>
    <li><strong>Decoding:</strong> Used Viterbi algorithm to find the most likely tag sequence for a given sentence using dynamic programming.</li>
    <li><strong>Probability Estimation:</strong>
      <ul>
        <li><code>P(ti | ti-1)</code> â€” transition probabilities from tag <em>ti-1</em> to <em>ti</em></li>
        <li><code>P(wi | ti)</code> â€” emission probabilities from tag <em>ti</em> to word <em>wi</em></li>
      </ul>
    </li>
    <li><strong>Evaluation:</strong> Achieved tagging accuracy of <strong>94.48%</strong> on the WSJ test set using gold standard tagging.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Python, WSJ Dataset, NumPy, Custom Viterbi Implementation</p>

  <p><strong>ğŸ¯ Applications:</strong> NLP pipelines, speech tagging in linguistic research, chatbot preprocessing, and syntactic parsing</p>
</div>

    <div class="project">
  <h3>ğŸ“ Neural Architecture Search using Genetic Algorithm</h3>
  <p><strong>Objective:</strong> Automate the design of optimal CNN architectures for the Fashion MNIST dataset using Genetic Algorithms, optimizing both accuracy and model complexity without manual trial-and-error.</p>

  <p><strong>ğŸ“Œ Methodology & Workflow:</strong></p>
  <ul>
    <li><strong>Base CNN Setup:</strong> 5-layer CNN architecture with alternating Normal (NC) and Reduction (RC) layers. Each NC layer used stride=1 and same padding; RC layers used stride=2 and valid padding.</li>
    <li><strong>Model Pool Creation:</strong> Trained 80 models with varying filter sizes (4â€“128) and random activation functions. Each model was stored with test accuracy and parameter count.</li>
    <li><strong>Fitness Function:</strong> Evaluated models based on: <code>fitness = test_accuracy - (param_count / max_param_count)</code>, rewarding high accuracy and fewer parameters.</li>
    <li><strong>Selection & Crossover:</strong> Selected top 4 models; performed crossover by encoding layer configurations into binary genome strings and exchanging segments at random crossover points.</li>
    <li><strong>Mutation & Evolution:</strong> Introduced random binary flips to encourage genetic diversity; iteratively refined the population based on performance gains.</li>
  </ul>

  <p><strong>ğŸ§  Model Insights:</strong></p>
  <ul>
    <li>Demonstrated clear trade-off between performance and parameter count.</li>
    <li>Produced final architectures with balanced efficiency and accuracy (e.g., 85.26% accuracy with only 59K parameters).</li>
    <li>Successfully avoided overfitting by using validation-split driven training.</li>
  </ul>

  <p><strong>ğŸ› ï¸ Tech Stack:</strong> Python, TensorFlow/Keras, NumPy, Fashion MNIST, Genetic Algorithm Implementation</p>

  <p><strong>ğŸ¯ Applications:</strong> Hyperparameter search automation, neural architecture design for embedded systems, lightweight CNN optimization for edge AI tasks</p>
</div>

  </section>

  <section id="contact">
    <h2>Contact Me</h2>
    <p>Email: <a href="mailto:pvkreddy0808@gmail.com">pvkreddy0808@gmail.com</a></p>
    <p>Phone: +91 9666019317</p>
    <p>LinkedIn: <a href="https://www.linkedin.com/in/vijay-kumar-reddy-p-303151154/" target="_blank">linkedin.com/in/vijay-kumar-reddy-p</a></p>
  </section>
<script>
  function toggleSection(id) {
  const section = document.getElementById(id);
  const btn = event.target;
  const isCollapsed = section.classList.toggle('collapsed');
  btn.textContent = isCollapsed ? 'â–¶' : 'â–¼';
}
</script>
</body>
</html>
